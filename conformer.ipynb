{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 16:34:43.406933: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-09 16:34:43.407001: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from tensorflow.keras.layers.experimental.preprocessing import PreprocessingLayer\n",
    "from typing import List, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecAugment(PreprocessingLayer):\n",
    "    def __init__(self, \n",
    "                 freq_mask_prob: float = 0.5,\n",
    "                 freq_mask_param: float = 10,\n",
    "                 time_mask_prob: float = 0.5,\n",
    "                 time_mask_param: float = 10):\n",
    "        self.freq_mask_prob = freq_mask_prob\n",
    "        self.freq_mask_param = freq_mask_param\n",
    "        self.time_mask_prob = time_mask_prob\n",
    "        self.time_mask_param = time_mask_param\n",
    "    \n",
    "    def call(self, features):\n",
    "        prob = tf.random.uniform([])\n",
    "        augmented = tfio.audio.freq_mask(features, param=self.freq_mask_param)\n",
    "        features = tf.cond(prob >= self.freq_mask_prob,\n",
    "                           lambda: augmented,\n",
    "                           lambda: features)\n",
    "        \n",
    "        prob = tf.random.uniform([])\n",
    "        augmented = tfio.audio.time_mask(features, param=self.time_mask_param)\n",
    "        features = tf.cond(prob >= self.time_mask_prob,\n",
    "                           lambda: augmented,\n",
    "                           lambda: features)\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 16:34:46.075546: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-09 16:34:46.075620: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-09 16:34:46.075665: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (asus): /proc/driver/nvidia/version does not exist\n",
      "2022-03-09 16:34:46.076482: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 0.          0.          1.7592382  ...  7.3736258   0.\n",
      "    10.7482    ]\n",
      "   [ 0.          0.          3.9257488  ...  3.7242112   0.\n",
      "     0.        ]\n",
      "   [ 0.          0.          7.5487366  ...  1.0469484   0.\n",
      "     8.181978  ]\n",
      "   ...\n",
      "   [ 0.          0.          1.0650812  ...  5.8976912   0.\n",
      "    11.519484  ]\n",
      "   [ 0.          0.          2.8196242  ...  0.          0.\n",
      "     1.1583123 ]\n",
      "   [ 0.          2.7070963   2.9822922  ...  0.          0.\n",
      "     2.8085012 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.          0.          0.         ...  3.8675451   0.\n",
      "     7.451819  ]\n",
      "   [ 0.          0.          0.         ... 10.164973    0.\n",
      "     0.        ]\n",
      "   [ 0.          0.85858864  0.         ... 11.796834    0.\n",
      "    11.693396  ]\n",
      "   ...\n",
      "   [ 0.          0.          5.906206   ...  7.208153    0.\n",
      "     9.236406  ]\n",
      "   [ 0.          0.          0.         ...  2.6752915   0.\n",
      "     6.1389604 ]\n",
      "   [ 0.          0.          0.         ...  8.276555    0.\n",
      "     0.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.          0.          0.         ...  5.247194    0.\n",
      "     4.044654  ]\n",
      "   [ 0.          0.          5.8788157  ...  7.118103    5.966441\n",
      "     1.9785281 ]\n",
      "   [ 1.1566799   0.          4.44055    ...  3.6192424   3.2461922\n",
      "     8.461875  ]\n",
      "   ...\n",
      "   [ 0.          0.          0.         ...  4.087638    0.\n",
      "     7.256315  ]\n",
      "   [ 0.          0.          0.         ...  4.3578396   0.\n",
      "     7.1054993 ]\n",
      "   [ 0.          0.          1.5552721  ...  4.6554384   1.0379431\n",
      "     3.1456056 ]]]], shape=(3, 1, 15, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "class ConvSubsampling(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 filters: List[int],\n",
    "                 kernel_size: List[int] = [3, 3],\n",
    "                 num_blocks: int = 1,\n",
    "                 num_layers_per_block: int = 2,\n",
    "                 dropout_rate: float = 0.0,\n",
    "                 name: str = \"ConvSubsampling\",\n",
    "                 **kwargs):\n",
    "        \n",
    "        super(ConvSubsampling, self).__init__(name=name, **kwargs)\n",
    "        \n",
    "        self.conv_blocks = tf.keras.Sequential()\n",
    "        for i in range(num_blocks):\n",
    "            convs = tf.keras.Sequential()\n",
    "            for _ in range(num_layers_per_block):\n",
    "                conv = tf.keras.layers.Conv2D(filters=filters[i],\n",
    "                                              kernel_size=kernel_size[i],\n",
    "                                              padding='same')\n",
    "                dropout = tf.keras.layers.Dropout(rate=dropout_rate)\n",
    "                relu = tf.keras.layers.ReLU()\n",
    "\n",
    "                convs.add(conv)\n",
    "                convs.add(dropout)\n",
    "                convs.add(relu)\n",
    "            \n",
    "            self.conv_blocks.add(convs)\n",
    "    \n",
    "    def call(self, inputs, training=False, **kwargs):\n",
    "        outputs = self.conv_blocks(inputs, training=training)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "batch_size, seq_len1, seq_len2, dim = 3, 1, 15, 512\n",
    "a = tf.random.uniform([batch_size, seq_len1, seq_len2, dim],\n",
    "                       minval=-40,\n",
    "                       maxval=40)\n",
    "conv_sub = ConvSubsampling(filters=[512, 512])\n",
    "b = conv_sub(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 32.955734  -12.525145   -3.701473  ...  20.555428   11.570231\n",
      "   -10.307843 ]\n",
      "  [ -6.0838504 -35.29328   -28.255804  ... -16.09479    28.688818\n",
      "    20.9091   ]\n",
      "  [ 26.145418   28.98612    -2.8145013 ...  23.870813   29.649874\n",
      "    -6.3953967]\n",
      "  ...\n",
      "  [ 27.683733   30.917841   -4.138617  ... -29.21204   -16.682503\n",
      "   -37.47012  ]\n",
      "  [ 19.270308   35.466263   37.385265  ... -32.332584   31.857155\n",
      "    37.144943 ]\n",
      "  [  3.6893954  24.89962    38.809315  ... -23.52759   -20.726103\n",
      "    23.821571 ]]\n",
      "\n",
      " [[ -1.7030383 -13.7418585  34.011215  ... -30.73392    -5.105972\n",
      "    16.99659  ]\n",
      "  [-23.19826    12.8521185 -32.671764  ... -18.971943    1.9581873\n",
      "    18.207022 ]\n",
      "  [ -0.8717662 -30.154459  -10.048917  ... -27.246363  -25.186249\n",
      "   -22.200712 ]\n",
      "  ...\n",
      "  [ 16.074629   10.158666  -38.069565  ...  36.170956  -26.120712\n",
      "    10.051651 ]\n",
      "  [-13.962652   13.160518   12.935482  ...  39.650917  -30.30099\n",
      "    31.140192 ]\n",
      "  [-14.427951   28.662128  -27.069307  ... -33.504307   23.567274\n",
      "   -13.703395 ]]\n",
      "\n",
      " [[-24.44972    19.96436   -22.762194  ...  18.99912    30.528336\n",
      "   -23.982578 ]\n",
      "  [ 23.264008   24.783415  -33.62712   ...  28.679604    3.7554457\n",
      "   -15.450772 ]\n",
      "  [-37.87597     7.0185356  32.392365  ...  19.220575   19.518696\n",
      "    -0.7938194]\n",
      "  ...\n",
      "  [ 27.35639    33.013535    1.3637508 ...   0.9453957 -25.019115\n",
      "    39.52124  ]\n",
      "  [ 12.877637   22.74047   -19.068136  ...  -9.506925   14.505321\n",
      "   -34.949135 ]\n",
      "  [ 35.813652    9.266899   14.460698  ...   8.66683     2.3867385\n",
      "    32.602097 ]]], shape=(3, 15, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "class FeedForwardModule(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 ffn_dim: int,\n",
    "                 dropout_rate: float = 0.4,\n",
    "                 expansion_factor: int = 4,\n",
    "                 output_reduction_factor: int = 0.5,\n",
    "                 name: str = \"FeedForwardModule\",\n",
    "                 **kwargs):\n",
    "        super(FeedForwardModule, self).__init__(name=name, **kwargs)\n",
    "        self.output_reduction_factor = output_reduction_factor\n",
    "\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Dense(ffn_dim * expansion_factor),\n",
    "            tf.keras.layers.Activation(tf.nn.silu),     # Swish activation with beta=1\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(ffn_dim),\n",
    "            tf.keras.layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "\n",
    "    def call(self, inputs, training=False, **kwargs):\n",
    "        outputs = self.ffn(inputs, training=training)\n",
    "        outputs = self.add([inputs, outputs * self.output_reduction_factor])\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "x = tf.random.uniform([batch_size, seq_len2, dim],\n",
    "                       minval=-40,\n",
    "                       maxval=40)\n",
    "ffn_module = FeedForwardModule(ffn_dim=512)\n",
    "y = ffn_module(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLU(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 name: str = \"GLU\",\n",
    "                 **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        mat1, mat2 = tf.split(inputs, 2, axis=-1)\n",
    "        mat2 = tf.nn.sigmoid(mat2)\n",
    "\n",
    "        return tf.math.multiply(mat1, mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 31.696167   -10.663067   -37.48425    ... -20.835714    11.380675\n",
      "   -12.265628  ]\n",
      "  [ 21.004318    18.080875   -33.19178    ...   9.084221   -12.156484\n",
      "    21.89629   ]\n",
      "  [ 37.9657      34.2879       5.5267434  ...  -1.2475196   22.66422\n",
      "     7.633396  ]\n",
      "  ...\n",
      "  [  4.7922487   26.616556   -34.79274    ...  -4.6261277   33.255142\n",
      "    14.239597  ]\n",
      "  [  2.743063    17.43611     30.946697   ...  26.331295     4.661812\n",
      "   -29.321018  ]\n",
      "  [ 19.288813   -24.23975     29.891933   ...   3.2656744  -36.67496\n",
      "    24.931236  ]]\n",
      "\n",
      " [[  0.15628254   3.2264771  -29.631634   ...  22.652111     2.2430909\n",
      "   -29.765686  ]\n",
      "  [ 25.349346   -12.552378   -28.984999   ...  39.130886   -15.609497\n",
      "   -18.216927  ]\n",
      "  [  1.0560838   34.77839     31.27607    ...  -0.43130168  37.300343\n",
      "   -20.287409  ]\n",
      "  ...\n",
      "  [-19.600626    -9.761104   -11.008283   ... -25.728521     0.72996974\n",
      "     4.361849  ]\n",
      "  [  7.263018    34.226643   -14.928892   ... -18.79405      0.8717155\n",
      "    34.57973   ]\n",
      "  [ 23.465448    35.974064    19.131897   ... -35.160362    29.947432\n",
      "   -35.27752   ]]\n",
      "\n",
      " [[ 16.196537   -36.53275     -7.9766765  ...  -1.5761448  -23.339828\n",
      "   -31.846325  ]\n",
      "  [  8.364799    36.827496   -35.933113   ... -20.780424     4.8763995\n",
      "    18.6882    ]\n",
      "  [ 22.466984    -9.857603    16.53706    ...  14.352603   -36.072006\n",
      "    38.423847  ]\n",
      "  ...\n",
      "  [ -7.0296326  -32.428833   -33.077663   ... -14.538837   -11.100403\n",
      "   -17.089903  ]\n",
      "  [-24.065538   -17.567753   -15.78876    ... -35.71612      1.9580421\n",
      "   -24.48286   ]\n",
      "  [ -2.870662     4.178525    27.622318   ... -24.002491   -18.811344\n",
      "   -17.278282  ]]], shape=(3, 15, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "class ConvolutionModule(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 filters: int,\n",
    "                 expansion_factor: int = 2,\n",
    "                 kernel_size: int = 3,\n",
    "                 dropout_rate: float = 0.4,\n",
    "                 name: str = \"ConvolutionModule\",\n",
    "                 **kwargs):\n",
    "        super(ConvolutionModule, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        self.conv_module = tf.keras.Sequential([\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Conv1D(filters=filters * expansion_factor,      # Pointwise Conv\n",
    "                                   kernel_size=1),\n",
    "            GLU(),\n",
    "            tf.keras.layers.Conv1D(filters=filters,                         # 1D Depthwise Conv\n",
    "                                   kernel_size=kernel_size,\n",
    "                                   padding='same',\n",
    "                                   groups=filters),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Activation(tf.nn.silu),\n",
    "            tf.keras.layers.Conv1D(filters=filters,                         # Pointwise Conv\n",
    "                                   kernel_size=1),\n",
    "            tf.keras.layers.Dropout(rate=dropout_rate)\n",
    "        ])\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "    def call(self, inputs, training=False, **kwargs):\n",
    "        outputs = self.conv_module(inputs, training=training)\n",
    "        outputs = self.add([inputs, outputs])\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "\n",
    "x = tf.random.uniform([batch_size, seq_len2, dim],\n",
    "                       minval=-40,\n",
    "                       maxval=40)\n",
    "cv = ConvolutionModule(filters=512)\n",
    "y = cv(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Headed Self-Attention Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([  3   1  15 512], shape=(4,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[ 0.00000000e+00  1.00000000e+00  0.00000000e+00 ...  1.00000000e+00\n",
      "    0.00000000e+00  1.00000000e+00]\n",
      "  [ 8.41470957e-01  5.40302277e-01  8.21856201e-01 ...  1.00000000e+00\n",
      "    1.03663326e-04  1.00000000e+00]\n",
      "  [ 9.09297407e-01 -4.16146815e-01  9.36414778e-01 ...  1.00000000e+00\n",
      "    2.07326651e-04  1.00000000e+00]\n",
      "  ...\n",
      "  [-5.36572933e-01  8.43853951e-01 -8.36262643e-01 ...  9.99999166e-01\n",
      "    1.24395953e-03  9.99999225e-01]\n",
      "  [ 4.20167029e-01  9.07446802e-01 -2.57669855e-02 ...  9.99999046e-01\n",
      "    1.34762272e-03  9.99999106e-01]\n",
      "  [ 9.90607381e-01  1.36737227e-01  8.06904018e-01 ...  9.99998868e-01\n",
      "    1.45128614e-03  9.99998927e-01]]], shape=(1, 15, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Implements the sinusoidal positional encoding function\n",
    "    Based on https://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 d_model: int = 512,\n",
    "                 name: str = \"PositionalEncoding\",\n",
    "                 **kwargs):\n",
    "        self.d_model = d_model\n",
    "        super(PositionalEncoding, self).__init__(name=name, **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d_model = input_shape[-1]\n",
    "        assert d_model == self.d_model, f\"d_model must be equal to the last dimension of the input, which is {self.d_model}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def encode(max_len, d_model):\n",
    "        pe = tf.zeros([max_len, d_model])\n",
    "        position = tf.expand_dims(tf.range(0, max_len), axis=1)\n",
    "        position = tf.cast(position, dtype=tf.float32)\n",
    "        div_term = tf.math.exp(tf.range(0, d_model, 2, dtype=tf.float32) * -(tf.math.log(10000.0) / float(d_model)))\n",
    "        \n",
    "        # Have to set up this way cause Tensorflow not allow assigning to EagerTensor\n",
    "        pe = tf.Variable(pe)\n",
    "        pe[:, 0::2].assign(tf.math.sin(position * div_term))\n",
    "        pe[:, 1::2].assign(tf.math.cos(position * div_term))\n",
    "        pe = tf.convert_to_tensor(pe)\n",
    "        pe = tf.expand_dims(pe, axis=0)\n",
    "\n",
    "        return pe\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        print(tf.shape(inputs))\n",
    "        max_len, d_model = tf.shape(inputs)[-2], tf.shape(inputs)[-1]\n",
    "        pe = self.encode(max_len, d_model)\n",
    "        # outputs = tf.math.add(inputs, pe)\n",
    "\n",
    "        return pe\n",
    "\n",
    "\n",
    "pos = PositionalEncoding()\n",
    "b = pos(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativeMHA(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Multi-head Attention with Relative Positional Embedding\n",
    "    Based on https://github.com/sooftware/conformer/blob/main/conformer/attention.py\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 num_heads: int = 8,\n",
    "                 d_model: int = 512,\n",
    "                 dropout_rate: float = 0.4,\n",
    "                 name: str = \"RelativeMHA\",\n",
    "                 **kwargs):\n",
    "        super(RelativeMHA, self).__init__(name=name, **kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.d_head = d_model // num_heads\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate=dropout_rate)\n",
    "\n",
    "        self.query_linear = tf.keras.layers.Dense(d_model)\n",
    "        self.key_linear = tf.keras.layers.Dense(d_model)\n",
    "        self.value_linear = tf.keras.layers.Dense(d_model)\n",
    "        self.pos_linear = tf.keras.layers.Dense(d_model)\n",
    "        self.out_linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.u_bias = tf.Variable(tf.keras.initializers.HeUniform()([self.num_heads, self.d_head]))\n",
    "        self.v_bias = tf.Variable(tf.keras.initializers.HeUniform()([self.num_heads, self.d_head]))\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d_model = input_shape[-1]\n",
    "        assert d_model == self.d_model, f\"d_model must be equal to the last dimension of the input, which is {self.d_model}\"\n",
    "        assert d_model % self.num_heads == 0, f\"num_heads must be divisible by {d_model}\"\n",
    "    \n",
    "    def call(self, \n",
    "             query: tf.Tensor,\n",
    "             key: tf.Tensor,\n",
    "             value: tf.Tensor,\n",
    "             pos_embedding: tf.Tensor,\n",
    "             training=False,\n",
    "             attention_mask: Optional[tf.Tensor] = None) -> tf.Tensor:\n",
    "\n",
    "        batch_size, seq_len = tf.shape(query)[0], tf.shape(query)[2]\n",
    "        query = tf.reshape(self.query_linear(query, training=training), [batch_size, -1, self.num_heads, self.d_head])\n",
    "        key = tf.transpose(tf.reshape(self.key_linear(key, training=training), [batch_size, -1, self.num_heads, self.d_head]), perm=[0, 2, 1, 3])\n",
    "        value = tf.transpose(tf.reshape(self.value_linear(value, training=training), [batch_size, -1, self.num_heads, self.d_head]), perm=[0, 2, 1, 3])\n",
    "        pos_embedding = tf.reshape(self.pos_linear(pos_embedding, training=training), [batch_size, -1, self.num_heads, self.d_head])\n",
    "\n",
    "        content_score = tf.linalg.matmul(tf.transpose(query + self.u_bias, perm=[0, 2, 1, 3]), tf.transpose(key, perm=[0, 1, 3, 2]))\n",
    "        pos_score = tf.linalg.matmul(tf.transpose(query + self.v_bias, perm=[0, 2, 1, 3]), tf.transpose(pos_embedding, perm=[0, 2, 3, 1]))\n",
    "        pos_score = self._relative_shift(pos_score)\n",
    "\n",
    "        score = (content_score + pos_score) / tf.math.sqrt(float(self.d_model))\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            attention_mask = tf.expand_dims(attention_mask, axis=1)\n",
    "            score = tf.where(attention_mask, tf.fill(tf.shape(score), -1e9), score)\n",
    "\n",
    "        attn = tf.nn.softmax(score, axis=-1)\n",
    "        attn = self.dropout(attn, training=training)\n",
    "        context = tf.transpose(tf.linalg.matmul(attn, value), perm=[0, 2, 1, 3])\n",
    "        context = self.out_linear(tf.reshape(context, [batch_size, -1, seq_len, self.d_model]), training=training)\n",
    "\n",
    "        return context\n",
    "\n",
    "    @staticmethod\n",
    "    def _relative_shift(pos_score: tf.Tensor) -> tf.Tensor:\n",
    "        batch_size, num_heads, seq_len1, seq_len2 = tf.shape(pos_score)\n",
    "        zeros = tf.zeros([batch_size, num_heads, seq_len1, 1])\n",
    "        padded_pos_score = tf.concat([zeros, pos_score], axis=-1)\n",
    "\n",
    "        padded_pos_score = tf.reshape(padded_pos_score, [batch_size, num_heads, seq_len2 + 1, seq_len1])\n",
    "        pos_score = tf.reshape(padded_pos_score[:, :, 1:], tf.shape(pos_score))\n",
    "\n",
    "        return pos_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 num_heads: int = 8,\n",
    "                 d_model: int = 512,\n",
    "                 dropout_rate: float = 0.4,\n",
    "                 name: str = \"MultiHeadedSelfAttention\",\n",
    "                 **kwargs):\n",
    "        super(MultiHeadedSelfAttention, self).__init__(name=name, **kwargs)\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "        self.attention = RelativeMHA(num_heads=num_heads, d_model=d_model, dropout_rate=dropout_rate)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, inputs: tf.Tensor, training=False, mask: Optional[tf.Tensor] = None) -> tf.Tensor:\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        pos_embedding = self.positional_encoding(inputs)\n",
    "        pos_embedding = tf.concat([pos_embedding for _ in range(batch_size)], axis=0)\n",
    "        \n",
    "        x = self.layer_norm(inputs, training=training)\n",
    "        x = self.attention(x, x, x, pos_embedding, training=training, attention_mask=mask)\n",
    "        x = self.dropout(x, training=training)  \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MHSAModule(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 head_size: int,\n",
    "                 num_heads: int = 8,\n",
    "                 d_model: int = 512,\n",
    "                 dropout_rate: float = 0.4,\n",
    "                 name: str = \"MHSAModule\",\n",
    "                 **kwargs):\n",
    "        super(MHSAModule, self).__init__(name=name, **kwargs)\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "        self.attention = tf.keras.layers.MultiHeadAttention(num_heads=num_heads,\n",
    "                                                            key_dim=head_size)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "    def call(self, inputs: tf.Tensor, training=False, mask: Optional[tf.Tensor] = None) -> tf.Tensor:\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        pos_embedding = self.positional_encoding(inputs)\n",
    "        pos_embedding = tf.concat([pos_embedding for _ in range(batch_size)], axis=0)\n",
    "        pos_embedding = tf.cast(pos_embedding, dtype=inputs.dtype)\n",
    "\n",
    "        outputs = self.layer_norm(inputs, training=training)\n",
    "        outputs = self.add([outputs, pos_embedding])\n",
    "        outputs = self.attention(outputs, outputs, outputs, attention_mask=mask, training=training)\n",
    "        outputs = self.dropout(outputs, training=training)\n",
    "        outputs = self.add([inputs, outputs])\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 num_blocks: int = 1,\n",
    "                 encoder_dim: int = 512,\n",
    "                 num_heads: int = 8,\n",
    "                 dropout_rate: float = 0.4,\n",
    "                 name: str = \"ConformerBlock\",\n",
    "                 **kwargs):\n",
    "        super(ConformerBlock, self).__init__(name=name, **kwargs)\n",
    "        self.num_blocks = num_blocks\n",
    "        self.ff_module = FeedForwardModule(encoder_dim)\n",
    "        self.attention = MultiHeadedSelfAttention(num_heads=num_heads, d_model=encoder_dim, dropout_rate=dropout_rate)\n",
    "        # self.attention = MHSAModule(head_size=encoder_dim, \n",
    "        #                             num_heads=num_heads, \n",
    "        #                             d_model=encoder_dim, \n",
    "        #                             dropout_rate=dropout_rate)\n",
    "        self.conv = ConvolutionModule(encoder_dim)\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs: tf.Tensor, training=False, mask: Optional[tf.Tensor] = None) -> tf.Tensor:\n",
    "        for _ in range(self.num_blocks):\n",
    "            x = self.ff_module(inputs, training=training)\n",
    "            x = self.attention(x, training=training, mask=mask)\n",
    "            x = self.conv(x, training=training)\n",
    "            x = self.ff_module(x, training=training)\n",
    "            x = self.layer_norm(x, training=training)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConformerEncoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 num_conv_filters: List[int],\n",
    "                 num_blocks: int = 1,\n",
    "                 encoder_dim: int = 512,\n",
    "                 num_heads: int = 8,\n",
    "                 dropout_rate: float = 0.4,\n",
    "                 num_classes:int = 10,\n",
    "                 include_top: bool = True,\n",
    "                 name: str = \"ConformerEncoder\",\n",
    "                 **kwargs):\n",
    "        super(ConformerEncoder, self).__init__(name=name, **kwargs)\n",
    "        self.include_top = include_top\n",
    "        self.conv_subsampling = ConvSubsampling(filters=num_conv_filters, dropout_rate=dropout_rate)\n",
    "        self.linear = tf.keras.layers.Dense(encoder_dim)\n",
    "        self.out_linear = tf.keras.layers.Dense(num_classes)\n",
    "        self.relu = tf.keras.layers.Activation(tf.nn.relu)\n",
    "        self.log_softmax = tf.keras.layers.Activation(tf.nn.log_softmax)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.conformer_block = ConformerBlock(num_blocks=num_blocks, encoder_dim=encoder_dim, num_heads=num_heads, dropout_rate=dropout_rate)\n",
    "\n",
    "    def call(self, inputs: tf.Tensor, training=False, mask: Optional[tf.Tensor] = None) -> tf.Tensor:\n",
    "        x = self.conv_subsampling(inputs, training=training)\n",
    "        x = self.linear(x, training=training)\n",
    "        x = self.relu(x, training=training)\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.conformer_block(x, training=training, mask=mask)\n",
    "\n",
    "        if self.include_top:\n",
    "            x = self.out_linear(x, training=training)\n",
    "            x = self.log_softmax(x, training=training)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, seq_len, dim = 3, 15, 512\n",
    "\n",
    "inputs = tf.random.uniform((batch_size, seq_len, dim),\n",
    "                            minval=-40,\n",
    "                            maxval=40)\n",
    "\n",
    "model = ConformerEncoder(num_conv_filters=[512, 512], num_blocks=1, encoder_dim=512, num_heads=8, dropout_rate=0.4, num_classes=10, include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([  3   1  15 512], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.expand_dims(inputs, axis=1)\n",
    "outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 3  1 15 10], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.shape(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d0e06370025cf99fea9cd4190fec9e2b7fe40a8b9f1c8c33a6cb9efc4531c404"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
